Kafka tutorial
https://kafka.apache.org/

Step 1:
Download the latest stable version of Apache Kafka from the official website.
wget http://www-us.apache.org/dist/kafka/0.10.2.1/kafka_2.10-0.10.2.1.tgz

Step 2: uncompress  the downloaded file
tar -xzf kafka-0.10.2.1-src.tgz

Step 3: Start the zookeeper server
Kafka uses ZooKeeper so you need to first start a ZooKeeper server if you don't already 
have one. You can use the convenience script packaged with kafka to get a quick-and-dirty
single-node ZooKeeper instance.
bin/zookeeper-server-start.sh config/zookeeper.properties

Note that the zookeeper service is available on port 2181 this is necessary when start kafka 
broker

Step 4: start kafka Server (Broker)
bin/kafka-server-start.sh config/server.properties

Step 3: Create a topic
Let's create a topic named "MyTopic" with a single partition and only one replica

bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test

We can now see that topic if we run the list topic command:
 bin/kafka-topics.sh --list --zookeeper localhost:2181
 
Step 4: Send some messages (Create producer to send message)
Kafka comes with a command line client that will take input from a file or from standard 
input and send it out as messages to the Kafka cluster. By default, each line will be 
sent as a separate message.

Run the producer and then type a few messages into the console to send to the server.

bin/kafka-console-producer.sh --broker-list localhost:9092 --topic MyTopic

Step 5: Start a consumer
Kafka also has a command line consumer that will dump out messages to standard output.

bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
 
Running Multiplebroker cluster 
Step 1: First we make a config file for each of the brokers.
Note: Multiple broker cannot run with same property file.

cp config/server.properties config/server-1.properties
cp config/server.properties config/server-2.properties

Now edit these new files and set the following properties:

config/server-1.properties:
    broker.id=1
    listeners=PLAINTEXT://:9093
    log.dir=/tmp/kafka-logs-1

config/server-2.properties:
    broker.id=2
    listeners=PLAINTEXT://:9094
    log.dir=/tmp/kafka-logs-2
	
The broker.id property is the unique and permanent name of each node in the cluster.
We have to override the port and log directory only because we are running these all
on the same machine and we want to keep the brokers from all trying to register on 
the same port or overwrite each other's data.


Step 2:
We already have Zookeeper and our single node started, so we just need to start the
two new nodes:
bin/kafka-server-start.sh config/server-1.properties &
bin/kafka-server-start.sh config/server-2.properties &


Step 3: Create New Topic with replication factor 3 and partition 2

bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic

Step 3:  To see Details of topics and broker details run the "describe topics" command:
bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic

 
Kafka API Java Example
Step 1: Creat a Maven project and add dependency related to kafka. Create a Producer Class
that will send message.

Step 2: Create jar file and run it on there jar file and run the consumer application to see all the message 
with the related topic. 

AVRO Tips
Download avro from
http://www-us.apache.org/dist/avro/stable/java/

java -jar 
java -jar avro-tools-1.8.2.jar compile schema ClickRecordV1.avsc .
 
 
Helpful websites
https://devops.profitbricks.com/tutorials/install-and-configure-apache-kafka-on-ubuntu-1604-1/

https://www.vultr.com/docs/how-to-install-apache-kafka-on-centos-7

https://www.tutorialspoint.com/apache_kafka/apache_kafka_installation_steps.htm

Look sbt 
http://www.scala-sbt.org/documentation.html

Look


